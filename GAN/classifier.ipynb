{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision.transforms import ToTensor, RandomAffine, RandomHorizontalFlip, RandomCrop\n",
    "\n",
    "from data import combine_transforms, load_data, OneHot\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_filters):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(n_filters, n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(n_filters, n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(n_filters)\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        \n",
    "        out = x + out\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class DownsampleConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_filters):\n",
    "        \n",
    "        super(DownsampleConvBlock, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(n_filters, 2*n_filters, 3, padding=1, stride=2),\n",
    "            nn.BatchNorm2d(2*n_filters),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2*n_filters, 2*n_filters, 3, padding=1),\n",
    "            nn.BatchNorm2d(2*n_filters)\n",
    "        )\n",
    "        \n",
    "        self.proj = nn.Conv2d(n_filters, 2*n_filters, 1, stride=2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        \n",
    "        x = self.proj(x)\n",
    "        \n",
    "        out = x + out\n",
    "        \n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "\n",
    "class Classififer(nn.Module):\n",
    "    \n",
    "    def block(self, in_filters, n_layers=3, down=True):\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        if down:\n",
    "            layers.append(DownsampleConvBlock(in_filters))\n",
    "            n_filters = 2 * in_filters\n",
    "        else:\n",
    "            layers.append(ConvBlock(in_filters))\n",
    "            n_filters = in_filters\n",
    "            \n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(ConvBlock(n_filters))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Classififer, self).__init__()\n",
    "        \n",
    "        n = 2\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            self.block(16, n_layers=2*n, down=False),\n",
    "            self.block(16, n_layers=2*n),\n",
    "            self.block(32, n_layers=2*n)\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 10), nn.Softmax(1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.reshape(-1, 64)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "n_epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = []\n",
    "# aug = [RandomAffine(30), RandomHorizontalFlip()]\n",
    "# aug = [RandomCrop(32, padding=4), RandomHorizontalFlip()]\n",
    "aug = [RandomAffine(30), RandomCrop(32, padding=4), RandomHorizontalFlip()]\n",
    "postp = [ToTensor()]\n",
    "target = []\n",
    "\n",
    "train_transform, test_transform, target_transform = combine_transforms(preprocessing=prep, \n",
    "                                                                        augmentations=aug, \n",
    "                                                                        postprocessing=postp, \n",
    "                                                                        target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_data('../data', \n",
    "                                      train_transform, test_transform, target_transform, \n",
    "                                      batch_size, use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(use_gpu=True):\n",
    "    model = Classififer()\n",
    "    \n",
    "    if use_gpu:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    return model\n",
    "\n",
    "def train_epoch(model, criterion, loader, optimizer):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    accs = []\n",
    "    \n",
    "    for batch in loader:\n",
    "\n",
    "        x, y = batch\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        accuracy = torch.mean((torch.argmax(y_pred, dim=1) == y).float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        accs.append(accuracy.item())\n",
    "    \n",
    "    return np.mean(losses), np.mean(accs)\n",
    "\n",
    "def evaluate_model(model, criterion, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    accs = []\n",
    "\n",
    "    for batch in loader:\n",
    "\n",
    "        x, y = batch\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "        accuracy = torch.mean((torch.argmax(y_pred, dim=1) == y).float())\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        accs.append(accuracy.item())\n",
    "    \n",
    "    return np.mean(losses), np.mean(accs)\n",
    "\n",
    "def train_model(model, criterion, train_loader, val_loader, n_epochs, optimizer):\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        loss, acc = train_epoch(model, criterion, train_loader, optimizer)\n",
    "        \n",
    "        val_loss, val_acc = evaluate_model(model, criterion, val_loader)\n",
    "        \n",
    "        print(f'epoch #{epoch} loss: {loss:.3f}, acc: {acc:.3f}, val_loss: {val_loss:.3f}, val_acc: {val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model(\n",
    "    use_gpu=use_gpu\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 loss: 2.120, acc: 0.342, val_loss: 2.025, val_acc: 0.442\n",
      "epoch #1 loss: 2.015, acc: 0.448, val_loss: 1.991, val_acc: 0.471\n",
      "epoch #2 loss: 1.977, acc: 0.486, val_loss: 1.983, val_acc: 0.475\n",
      "epoch #3 loss: 1.951, acc: 0.513, val_loss: 1.930, val_acc: 0.533\n",
      "epoch #4 loss: 1.929, acc: 0.536, val_loss: 1.932, val_acc: 0.530\n",
      "epoch #5 loss: 1.908, acc: 0.556, val_loss: 1.892, val_acc: 0.569\n",
      "epoch #6 loss: 1.890, acc: 0.575, val_loss: 1.863, val_acc: 0.596\n",
      "epoch #7 loss: 1.876, acc: 0.588, val_loss: 1.868, val_acc: 0.594\n",
      "epoch #8 loss: 1.865, acc: 0.598, val_loss: 1.846, val_acc: 0.615\n",
      "epoch #9 loss: 1.855, acc: 0.607, val_loss: 1.835, val_acc: 0.627\n",
      "epoch #10 loss: 1.844, acc: 0.619, val_loss: 1.826, val_acc: 0.636\n",
      "epoch #11 loss: 1.834, acc: 0.627, val_loss: 1.815, val_acc: 0.646\n",
      "epoch #12 loss: 1.828, acc: 0.635, val_loss: 1.797, val_acc: 0.665\n",
      "epoch #13 loss: 1.819, acc: 0.644, val_loss: 1.801, val_acc: 0.663\n",
      "epoch #14 loss: 1.812, acc: 0.652, val_loss: 1.792, val_acc: 0.672\n",
      "epoch #15 loss: 1.809, acc: 0.653, val_loss: 1.774, val_acc: 0.686\n",
      "epoch #16 loss: 1.799, acc: 0.664, val_loss: 1.777, val_acc: 0.685\n",
      "epoch #17 loss: 1.795, acc: 0.668, val_loss: 1.780, val_acc: 0.680\n",
      "epoch #18 loss: 1.789, acc: 0.674, val_loss: 1.763, val_acc: 0.701\n",
      "epoch #19 loss: 1.785, acc: 0.678, val_loss: 1.763, val_acc: 0.700\n",
      "epoch #20 loss: 1.782, acc: 0.682, val_loss: 1.769, val_acc: 0.693\n",
      "epoch #21 loss: 1.779, acc: 0.683, val_loss: 1.749, val_acc: 0.713\n",
      "epoch #22 loss: 1.771, acc: 0.692, val_loss: 1.741, val_acc: 0.723\n",
      "epoch #23 loss: 1.767, acc: 0.696, val_loss: 1.743, val_acc: 0.718\n",
      "epoch #24 loss: 1.764, acc: 0.698, val_loss: 1.745, val_acc: 0.715\n",
      "epoch #25 loss: 1.759, acc: 0.703, val_loss: 1.737, val_acc: 0.725\n",
      "epoch #26 loss: 1.757, acc: 0.707, val_loss: 1.742, val_acc: 0.720\n",
      "epoch #27 loss: 1.751, acc: 0.713, val_loss: 1.751, val_acc: 0.710\n",
      "epoch #28 loss: 1.744, acc: 0.719, val_loss: 1.738, val_acc: 0.723\n",
      "epoch #29 loss: 1.744, acc: 0.719, val_loss: 1.722, val_acc: 0.740\n",
      "epoch #30 loss: 1.740, acc: 0.723, val_loss: 1.733, val_acc: 0.727\n",
      "epoch #31 loss: 1.739, acc: 0.724, val_loss: 1.717, val_acc: 0.745\n",
      "epoch #32 loss: 1.731, acc: 0.732, val_loss: 1.717, val_acc: 0.743\n",
      "epoch #33 loss: 1.730, acc: 0.733, val_loss: 1.718, val_acc: 0.743\n",
      "epoch #34 loss: 1.731, acc: 0.731, val_loss: 1.714, val_acc: 0.747\n",
      "epoch #35 loss: 1.727, acc: 0.735, val_loss: 1.713, val_acc: 0.749\n",
      "epoch #36 loss: 1.724, acc: 0.739, val_loss: 1.712, val_acc: 0.749\n",
      "epoch #37 loss: 1.720, acc: 0.743, val_loss: 1.706, val_acc: 0.755\n",
      "epoch #38 loss: 1.716, acc: 0.748, val_loss: 1.702, val_acc: 0.760\n",
      "epoch #39 loss: 1.715, acc: 0.747, val_loss: 1.698, val_acc: 0.765\n",
      "epoch #40 loss: 1.714, acc: 0.748, val_loss: 1.704, val_acc: 0.758\n",
      "epoch #41 loss: 1.712, acc: 0.750, val_loss: 1.703, val_acc: 0.758\n",
      "epoch #42 loss: 1.709, acc: 0.753, val_loss: 1.696, val_acc: 0.764\n",
      "epoch #43 loss: 1.706, acc: 0.757, val_loss: 1.703, val_acc: 0.759\n",
      "epoch #44 loss: 1.704, acc: 0.758, val_loss: 1.693, val_acc: 0.768\n",
      "epoch #45 loss: 1.700, acc: 0.763, val_loss: 1.692, val_acc: 0.771\n",
      "epoch #46 loss: 1.702, acc: 0.760, val_loss: 1.699, val_acc: 0.764\n",
      "epoch #47 loss: 1.699, acc: 0.764, val_loss: 1.681, val_acc: 0.779\n",
      "epoch #48 loss: 1.697, acc: 0.766, val_loss: 1.692, val_acc: 0.769\n",
      "epoch #49 loss: 1.694, acc: 0.769, val_loss: 1.690, val_acc: 0.770\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model, \n",
    "    criterion,\n",
    "    train_loader, \n",
    "    test_loader,\n",
    "    n_epochs,\n",
    "    optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 loss: 2.142, acc: 0.314, val_loss: 2.065, val_acc: 0.398\n",
      "epoch #1 loss: 2.011, acc: 0.455, val_loss: 1.987, val_acc: 0.475\n",
      "epoch #2 loss: 1.950, acc: 0.517, val_loss: 1.938, val_acc: 0.523\n",
      "epoch #3 loss: 1.914, acc: 0.553, val_loss: 1.909, val_acc: 0.551\n",
      "epoch #4 loss: 1.884, acc: 0.582, val_loss: 1.896, val_acc: 0.567\n",
      "epoch #5 loss: 1.865, acc: 0.601, val_loss: 1.889, val_acc: 0.571\n",
      "epoch #6 loss: 1.847, acc: 0.618, val_loss: 1.850, val_acc: 0.610\n",
      "epoch #7 loss: 1.832, acc: 0.633, val_loss: 1.859, val_acc: 0.604\n",
      "epoch #8 loss: 1.821, acc: 0.643, val_loss: 1.829, val_acc: 0.633\n",
      "epoch #9 loss: 1.809, acc: 0.654, val_loss: 1.806, val_acc: 0.654\n",
      "epoch #10 loss: 1.798, acc: 0.666, val_loss: 1.789, val_acc: 0.674\n",
      "epoch #11 loss: 1.786, acc: 0.678, val_loss: 1.795, val_acc: 0.669\n",
      "epoch #12 loss: 1.778, acc: 0.686, val_loss: 1.783, val_acc: 0.680\n",
      "epoch #13 loss: 1.770, acc: 0.695, val_loss: 1.804, val_acc: 0.656\n",
      "epoch #14 loss: 1.762, acc: 0.702, val_loss: 1.768, val_acc: 0.692\n",
      "epoch #15 loss: 1.753, acc: 0.711, val_loss: 1.768, val_acc: 0.693\n",
      "epoch #16 loss: 1.745, acc: 0.718, val_loss: 1.752, val_acc: 0.709\n",
      "epoch #17 loss: 1.737, acc: 0.728, val_loss: 1.734, val_acc: 0.728\n",
      "epoch #18 loss: 1.730, acc: 0.734, val_loss: 1.763, val_acc: 0.699\n",
      "epoch #19 loss: 1.727, acc: 0.736, val_loss: 1.758, val_acc: 0.703\n",
      "epoch #20 loss: 1.720, acc: 0.744, val_loss: 1.728, val_acc: 0.734\n",
      "epoch #21 loss: 1.715, acc: 0.750, val_loss: 1.742, val_acc: 0.719\n",
      "epoch #22 loss: 1.710, acc: 0.753, val_loss: 1.729, val_acc: 0.734\n",
      "epoch #23 loss: 1.702, acc: 0.762, val_loss: 1.722, val_acc: 0.740\n",
      "epoch #24 loss: 1.701, acc: 0.764, val_loss: 1.723, val_acc: 0.739\n",
      "epoch #25 loss: 1.696, acc: 0.768, val_loss: 1.716, val_acc: 0.745\n",
      "epoch #26 loss: 1.692, acc: 0.771, val_loss: 1.725, val_acc: 0.737\n",
      "epoch #27 loss: 1.690, acc: 0.773, val_loss: 1.715, val_acc: 0.746\n",
      "epoch #28 loss: 1.686, acc: 0.777, val_loss: 1.699, val_acc: 0.763\n",
      "epoch #29 loss: 1.682, acc: 0.782, val_loss: 1.700, val_acc: 0.762\n",
      "epoch #30 loss: 1.680, acc: 0.782, val_loss: 1.691, val_acc: 0.770\n",
      "epoch #31 loss: 1.675, acc: 0.789, val_loss: 1.689, val_acc: 0.772\n",
      "epoch #32 loss: 1.674, acc: 0.790, val_loss: 1.703, val_acc: 0.757\n",
      "epoch #33 loss: 1.669, acc: 0.794, val_loss: 1.693, val_acc: 0.769\n",
      "epoch #34 loss: 1.668, acc: 0.795, val_loss: 1.680, val_acc: 0.780\n",
      "epoch #35 loss: 1.662, acc: 0.801, val_loss: 1.680, val_acc: 0.784\n",
      "epoch #36 loss: 1.661, acc: 0.803, val_loss: 1.688, val_acc: 0.773\n",
      "epoch #37 loss: 1.656, acc: 0.807, val_loss: 1.673, val_acc: 0.790\n",
      "epoch #38 loss: 1.656, acc: 0.808, val_loss: 1.683, val_acc: 0.777\n",
      "epoch #39 loss: 1.656, acc: 0.806, val_loss: 1.679, val_acc: 0.784\n",
      "epoch #40 loss: 1.651, acc: 0.812, val_loss: 1.670, val_acc: 0.791\n",
      "epoch #41 loss: 1.649, acc: 0.814, val_loss: 1.665, val_acc: 0.795\n",
      "epoch #42 loss: 1.647, acc: 0.817, val_loss: 1.664, val_acc: 0.797\n",
      "epoch #43 loss: 1.647, acc: 0.817, val_loss: 1.663, val_acc: 0.798\n",
      "epoch #44 loss: 1.644, acc: 0.818, val_loss: 1.671, val_acc: 0.790\n",
      "epoch #45 loss: 1.641, acc: 0.823, val_loss: 1.659, val_acc: 0.802\n",
      "epoch #46 loss: 1.639, acc: 0.824, val_loss: 1.667, val_acc: 0.794\n",
      "epoch #47 loss: 1.638, acc: 0.825, val_loss: 1.660, val_acc: 0.800\n",
      "epoch #48 loss: 1.635, acc: 0.828, val_loss: 1.661, val_acc: 0.800\n",
      "epoch #49 loss: 1.633, acc: 0.831, val_loss: 1.659, val_acc: 0.801\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model, \n",
    "    criterion,\n",
    "    train_loader, \n",
    "    test_loader,\n",
    "    n_epochs,\n",
    "    optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch #0 loss: 2.149, acc: 0.306, val_loss: 2.078, val_acc: 0.377\n",
      "epoch #1 loss: 2.052, acc: 0.408, val_loss: 2.016, val_acc: 0.440\n",
      "epoch #2 loss: 2.008, acc: 0.454, val_loss: 1.985, val_acc: 0.476\n",
      "epoch #3 loss: 1.979, acc: 0.484, val_loss: 1.958, val_acc: 0.501\n",
      "epoch #4 loss: 1.960, acc: 0.503, val_loss: 1.935, val_acc: 0.523\n",
      "epoch #5 loss: 1.937, acc: 0.527, val_loss: 1.913, val_acc: 0.549\n",
      "epoch #6 loss: 1.924, acc: 0.538, val_loss: 1.897, val_acc: 0.565\n",
      "epoch #7 loss: 1.908, acc: 0.556, val_loss: 1.900, val_acc: 0.559\n",
      "epoch #8 loss: 1.897, acc: 0.566, val_loss: 1.871, val_acc: 0.588\n",
      "epoch #9 loss: 1.888, acc: 0.575, val_loss: 1.881, val_acc: 0.579\n",
      "epoch #10 loss: 1.878, acc: 0.584, val_loss: 1.864, val_acc: 0.597\n",
      "epoch #11 loss: 1.871, acc: 0.591, val_loss: 1.844, val_acc: 0.616\n",
      "epoch #12 loss: 1.863, acc: 0.600, val_loss: 1.854, val_acc: 0.606\n",
      "epoch #13 loss: 1.854, acc: 0.607, val_loss: 1.836, val_acc: 0.625\n",
      "epoch #14 loss: 1.849, acc: 0.614, val_loss: 1.820, val_acc: 0.639\n",
      "epoch #15 loss: 1.843, acc: 0.619, val_loss: 1.835, val_acc: 0.624\n",
      "epoch #16 loss: 1.837, acc: 0.626, val_loss: 1.829, val_acc: 0.632\n",
      "epoch #17 loss: 1.833, acc: 0.629, val_loss: 1.819, val_acc: 0.641\n",
      "epoch #18 loss: 1.827, acc: 0.635, val_loss: 1.801, val_acc: 0.659\n",
      "epoch #19 loss: 1.819, acc: 0.643, val_loss: 1.793, val_acc: 0.666\n",
      "epoch #20 loss: 1.815, acc: 0.646, val_loss: 1.780, val_acc: 0.682\n",
      "epoch #21 loss: 1.810, acc: 0.652, val_loss: 1.785, val_acc: 0.675\n",
      "epoch #22 loss: 1.803, acc: 0.660, val_loss: 1.783, val_acc: 0.677\n",
      "epoch #23 loss: 1.801, acc: 0.662, val_loss: 1.786, val_acc: 0.674\n",
      "epoch #24 loss: 1.797, acc: 0.665, val_loss: 1.772, val_acc: 0.688\n",
      "epoch #25 loss: 1.795, acc: 0.667, val_loss: 1.784, val_acc: 0.676\n",
      "epoch #26 loss: 1.789, acc: 0.673, val_loss: 1.791, val_acc: 0.670\n",
      "epoch #27 loss: 1.785, acc: 0.677, val_loss: 1.754, val_acc: 0.708\n",
      "epoch #28 loss: 1.783, acc: 0.679, val_loss: 1.756, val_acc: 0.703\n",
      "epoch #29 loss: 1.777, acc: 0.685, val_loss: 1.754, val_acc: 0.708\n",
      "epoch #30 loss: 1.775, acc: 0.687, val_loss: 1.760, val_acc: 0.700\n",
      "epoch #31 loss: 1.774, acc: 0.688, val_loss: 1.747, val_acc: 0.713\n",
      "epoch #32 loss: 1.768, acc: 0.694, val_loss: 1.741, val_acc: 0.721\n",
      "epoch #33 loss: 1.766, acc: 0.696, val_loss: 1.744, val_acc: 0.717\n",
      "epoch #34 loss: 1.762, acc: 0.700, val_loss: 1.742, val_acc: 0.719\n",
      "epoch #35 loss: 1.761, acc: 0.701, val_loss: 1.743, val_acc: 0.718\n",
      "epoch #36 loss: 1.756, acc: 0.707, val_loss: 1.730, val_acc: 0.732\n",
      "epoch #37 loss: 1.754, acc: 0.707, val_loss: 1.735, val_acc: 0.725\n",
      "epoch #38 loss: 1.754, acc: 0.708, val_loss: 1.729, val_acc: 0.734\n",
      "epoch #39 loss: 1.748, acc: 0.714, val_loss: 1.719, val_acc: 0.744\n",
      "epoch #40 loss: 1.745, acc: 0.717, val_loss: 1.717, val_acc: 0.743\n",
      "epoch #41 loss: 1.744, acc: 0.718, val_loss: 1.729, val_acc: 0.732\n",
      "epoch #42 loss: 1.743, acc: 0.720, val_loss: 1.727, val_acc: 0.732\n",
      "epoch #43 loss: 1.738, acc: 0.724, val_loss: 1.718, val_acc: 0.744\n",
      "epoch #44 loss: 1.738, acc: 0.724, val_loss: 1.718, val_acc: 0.742\n",
      "epoch #45 loss: 1.736, acc: 0.726, val_loss: 1.756, val_acc: 0.704\n",
      "epoch #46 loss: 1.734, acc: 0.728, val_loss: 1.717, val_acc: 0.744\n",
      "epoch #47 loss: 1.733, acc: 0.729, val_loss: 1.710, val_acc: 0.749\n",
      "epoch #48 loss: 1.731, acc: 0.731, val_loss: 1.701, val_acc: 0.761\n",
      "epoch #49 loss: 1.728, acc: 0.734, val_loss: 1.693, val_acc: 0.768\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model, \n",
    "    criterion,\n",
    "    train_loader, \n",
    "    test_loader,\n",
    "    n_epochs,\n",
    "    optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
